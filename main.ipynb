{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://www.kaggle.com/code/sohier/optiver-2023-basic-submission-demo/notebook\n# 提出はこのapiを使うこと\n\n# '''\n# An unlocked version of the timeseries API intended for testing alternate inputs.\n# Mirrors the production timeseries API in the crucial respects, but won't be as fast.\n\n# ONLY works afer the first three variables in MockAPI.__init__ are populated.\n# '''\n\n# from typing import Sequence, Tuple\n\n# import pandas as pd\n\n\n# class MockApi:\n#     def __init__(self):\n#         '''\n#         YOU MUST UPDATE THE FIRST THREE LINES of this method.\n#         They've been intentionally left in an invalid state.\n\n#         Variables to set:\n#             input_paths: a list of two or more paths to the csv files to be served\n#             group_id_column: the column that identifies which groups of rows the API should serve.\n#                 A call to iter_test serves all rows of all dataframes with the current group ID value.\n#             export_group_id_column: if true, the dataframes iter_test serves will include the group_id_column values.\n#         '''\n#         self.input_paths: Sequence[str] =\n#         self.group_id_column: str = \n#         self.export_group_id_column: bool = True\n#         # iter_test is only designed to support at least two dataframes, such as test and sample_submission\n#         assert len(self.input_paths) >= 2\n\n#         self._status = 'initialized'\n#         self.predictions = []\n\n#     def iter_test(self) -> Tuple[pd.DataFrame]:\n#         '''\n#         Loads all of the dataframes specified in self.input_paths,\n#         then yields all rows in those dataframes that equal the current self.group_id_column value.\n#         '''\n#         if self._status != 'initialized':\n\n#             raise Exception('WARNING: the real API can only iterate over `iter_test()` once.')\n\n#         dataframes = []\n#         for pth in self.input_paths:\n#             dataframes.append(pd.read_csv(pth, low_memory=False))\n#         group_order = dataframes[0][self.group_id_column].drop_duplicates().tolist()\n#         dataframes = [df.set_index(self.group_id_column) for df in dataframes]\n\n#         for group_id in group_order:\n#             self._status = 'prediction_needed'\n#             current_data = []\n#             for df in dataframes:\n#                 cur_df = df.loc[group_id].copy()\n#                 # returning single line dataframes from df.loc requires special handling\n#                 if not isinstance(cur_df, pd.DataFrame):\n#                     cur_df = pd.DataFrame({a: b for a, b in zip(cur_df.index.values, cur_df.values)}, index=[group_id])\n#                     cur_df.index.name = self.group_id_column\n#                 cur_df = cur_df.reset_index(drop=not(self.export_group_id_column))\n#                 current_data.append(cur_df)\n#             yield tuple(current_data)\n\n#             while self._status != 'prediction_received':\n#                 print('You must call `predict()` successfully before you can continue with `iter_test()`', flush=True)\n#                 yield None\n\n#         with open('submission.csv', 'w') as f_open:\n#             pd.concat(self.predictions).to_csv(f_open, index=False)\n#         self._status = 'finished'\n\n#     def predict(self, user_predictions: pd.DataFrame):\n#         '''\n#         Accepts and stores the user's predictions and unlocks iter_test once that is done\n#         '''\n#         if self._status == 'finished':\n#             raise Exception('You have already made predictions for the full test set.')\n#         if self._status != 'prediction_needed':\n#             raise Exception('You must get the next test sample from `iter_test()` first.')\n#         if not isinstance(user_predictions, pd.DataFrame):\n#             raise Exception('You must provide a DataFrame.')\n\n#         self.predictions.append(user_predictions)\n#         self._status = 'prediction_received'\n\n\n# def make_env():\n#     return MockApi()\n\n# env = optiver2023.make_env()\n# iter_test = env.iter_test()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:02:05.443267Z","iopub.execute_input":"2023-11-12T06:02:05.443534Z","iopub.status.idle":"2023-11-12T06:02:05.451686Z","shell.execute_reply.started":"2023-11-12T06:02:05.443509Z","shell.execute_reply":"2023-11-12T06:02:05.450829Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# %config Completer.use_jedi = False\n\nimport os\nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport optuna\nimport optiver2023\nimport random\nrandom.seed(100)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nprint('python:', sys.version)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-12T06:02:05.453456Z","iopub.execute_input":"2023-11-12T06:02:05.453792Z","iopub.status.idle":"2023-11-12T06:02:12.407744Z","shell.execute_reply.started":"2023-11-12T06:02:05.453762Z","shell.execute_reply":"2023-11-12T06:02:12.406821Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n/kaggle/input/optiver-trading-at-the-close/train.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\ntest = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv')\nrevealed_targets = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:02:12.409348Z","iopub.execute_input":"2023-11-12T06:02:12.409950Z","iopub.status.idle":"2023-11-12T06:02:30.148190Z","shell.execute_reply.started":"2023-11-12T06:02:12.409923Z","shell.execute_reply":"2023-11-12T06:02:30.147399Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:02:30.149437Z","iopub.execute_input":"2023-11-12T06:02:30.150206Z","iopub.status.idle":"2023-11-12T06:02:30.177261Z","shell.execute_reply.started":"2023-11-12T06:02:30.150172Z","shell.execute_reply":"2023-11-12T06:02:30.176453Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n0         0        0                  0      3180602.69   \n1         1        0                  0       166603.91   \n2         2        0                  0       302879.87   \n3         3        0                  0     11917682.27   \n4         4        0                  0       447549.96   \n\n   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n0                        1         0.999812   13380276.64        NaN   \n1                       -1         0.999896    1642214.25        NaN   \n2                       -1         0.999561    1819368.03        NaN   \n3                       -1         1.000171   18389745.62        NaN   \n4                       -1         0.999532   17860614.95        NaN   \n\n   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n\n   time_id row_id  \n0        0  0_0_0  \n1        0  0_0_1  \n2        0  0_0_2  \n3        0  0_0_3  \n4        0  0_0_4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>date_id</th>\n      <th>seconds_in_bucket</th>\n      <th>imbalance_size</th>\n      <th>imbalance_buy_sell_flag</th>\n      <th>reference_price</th>\n      <th>matched_size</th>\n      <th>far_price</th>\n      <th>near_price</th>\n      <th>bid_price</th>\n      <th>bid_size</th>\n      <th>ask_price</th>\n      <th>ask_size</th>\n      <th>wap</th>\n      <th>target</th>\n      <th>time_id</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3180602.69</td>\n      <td>1</td>\n      <td>0.999812</td>\n      <td>13380276.64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999812</td>\n      <td>60651.50</td>\n      <td>1.000026</td>\n      <td>8493.03</td>\n      <td>1.0</td>\n      <td>-3.029704</td>\n      <td>0</td>\n      <td>0_0_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>166603.91</td>\n      <td>-1</td>\n      <td>0.999896</td>\n      <td>1642214.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999896</td>\n      <td>3233.04</td>\n      <td>1.000660</td>\n      <td>20605.09</td>\n      <td>1.0</td>\n      <td>-5.519986</td>\n      <td>0</td>\n      <td>0_0_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>302879.87</td>\n      <td>-1</td>\n      <td>0.999561</td>\n      <td>1819368.03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999403</td>\n      <td>37956.00</td>\n      <td>1.000298</td>\n      <td>18995.00</td>\n      <td>1.0</td>\n      <td>-8.389950</td>\n      <td>0</td>\n      <td>0_0_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11917682.27</td>\n      <td>-1</td>\n      <td>1.000171</td>\n      <td>18389745.62</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999999</td>\n      <td>2324.90</td>\n      <td>1.000214</td>\n      <td>479032.40</td>\n      <td>1.0</td>\n      <td>-4.010200</td>\n      <td>0</td>\n      <td>0_0_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>447549.96</td>\n      <td>-1</td>\n      <td>0.999532</td>\n      <td>17860614.95</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.999394</td>\n      <td>16485.54</td>\n      <td>1.000016</td>\n      <td>434.10</td>\n      <td>1.0</td>\n      <td>-7.349849</td>\n      <td>0</td>\n      <td>0_0_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"revealed_targets.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:02:30.179214Z","iopub.execute_input":"2023-11-12T06:02:30.179870Z","iopub.status.idle":"2023-11-12T06:02:30.191808Z","shell.execute_reply.started":"2023-11-12T06:02:30.179837Z","shell.execute_reply":"2023-11-12T06:02:30.190879Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   stock_id  date_id  seconds_in_bucket  time_id  revealed_target  \\\n0       0.0      478                  0    26290        -2.310276   \n1       1.0      478                  0    26290       -12.850165   \n2       2.0      478                  0    26290        -0.439882   \n3       3.0      478                  0    26290         7.259846   \n4       4.0      478                  0    26290         4.780292   \n\n   revealed_date_id  revealed_time_id  \n0             477.0           26235.0  \n1             477.0           26235.0  \n2             477.0           26235.0  \n3             477.0           26235.0  \n4             477.0           26235.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stock_id</th>\n      <th>date_id</th>\n      <th>seconds_in_bucket</th>\n      <th>time_id</th>\n      <th>revealed_target</th>\n      <th>revealed_date_id</th>\n      <th>revealed_time_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>478</td>\n      <td>0</td>\n      <td>26290</td>\n      <td>-2.310276</td>\n      <td>477.0</td>\n      <td>26235.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>478</td>\n      <td>0</td>\n      <td>26290</td>\n      <td>-12.850165</td>\n      <td>477.0</td>\n      <td>26235.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>478</td>\n      <td>0</td>\n      <td>26290</td>\n      <td>-0.439882</td>\n      <td>477.0</td>\n      <td>26235.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>478</td>\n      <td>0</td>\n      <td>26290</td>\n      <td>7.259846</td>\n      <td>477.0</td>\n      <td>26235.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>478</td>\n      <td>0</td>\n      <td>26290</td>\n      <td>4.780292</td>\n      <td>477.0</td>\n      <td>26235.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# distribution except for stock_id, date_id, seconds_in_bucket, row_id\n# fig = plt.figure()\n# ax = fig.add_subplot(1,1,1)\n# plt_train = train.drop(['stock_id','row_id','seconds_in_bucket','row_id'], axis=1)\n# boxplot_labels = plt_train.columns\n# sns.boxplot(train['imbalance_size'])","metadata":{"execution":{"iopub.status.busy":"2023-11-12T07:08:54.441252Z","iopub.execute_input":"2023-11-12T07:08:54.441982Z","iopub.status.idle":"2023-11-12T07:08:54.446058Z","shell.execute_reply.started":"2023-11-12T07:08:54.441948Z","shell.execute_reply":"2023-11-12T07:08:54.445104Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# 欠損値がどのくらいあるか見てみる\n# 今回のデータは幅が広そうなので中央値でnull埋め\n\nnull_data = train.isnull()\n\nprint('data size:', len(train))\nprint('null sum', null_data.sum())\nprint('===============================')\n\nreduced_train = train[:1000] # データ量が多すぎるのでいったん1000件くらいで\n\nfillna_reduced_train = pd.DataFrame()\nfor col_name in reduced_train:\n    fillna_train = train_x[col_name].fillna(train[col_name].median())\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}